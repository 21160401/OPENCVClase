{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red neuronal, se caracteriza por el conjunto de capas de **Neuronas**, que se basan en el cálculo de probabilidades para realizar predicciones, su unidad básica es el perceptrón.\n",
    "Las *Redes Neuronales Convolucionales*, se usan para la clasificación de imágenes y la detección de objetos en imágenes, se basan en conjuntos de redes neuronales que utilizan el proceso de convolución para procesar la imágen.\n",
    "Es decir, se recibe una imágen a la entrada, esta imagen es procesada en pixeles, cada cierta cantidad de pixeles la imagen es procesada por convolución por medio de un kernel, de esta manera por medio de ueros se obtiene datos de la imagen, debido a una imagen tiene muchos pixeles, después de la convolución se obtienen grandes cantidades de datos, entonces se vuelve necesario ir reduciendo el tamaño de la imagen dejando características importantes unicamente.\n",
    "La manera de clasificar una imagen como verdadera o falsa reespecto a algo se hace por medio de la red, cada entrada de una neurona tiene un peso asignado que se multiplica por el valor de la entra, las neuronas tienen muchas entradas, tantas como pixeles tiene la imagen, estas multiplicaciones se suman y pasan por un proceso llamdo activación, la activación va dando resultados se ciertas características, a la salida de la red se tienen tantas neuronas como objetos se desea clasificar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist\n",
    "Es un data set de imagenes de 28 x 28 pixeles, estas imágenes son digitos escritos a mano, el propósito de este ejercicio es realizar una clasificación adecuada de los digitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from Load_and_Preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La CNN utiliza 2 capas neuronales, la primera utiliza como función de activación relu y es la capa oculta de la red y la segunda utiliza softmax y es lacapa de salida de la red\n",
    "# Relu\n",
    "Es una función de activación que se utiza en la hidden layer o capa oculta de la red neuronal. Su valor se consigue tomando como valor máximo el valor de entrada de la neurona, es básicamente una pendiente, se utiliza debido a que al ser una pendiente simplifica los cálculos del **back propagation** para ajustar los pesos de las entradas de las neuronas.\n",
    "# Softmax\n",
    "Es la función de activación que se utiliza en una red neuronal que no tiene salida binomial, se caracteriza porque normaliza los valores de las entradas de las neuronas de la última capa en valores de 0 a 1, esto se consigue cálculando el exponencial de cada entrada y dividiendolo entre la suma de todas las entradas de la última capa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test, input_shape = load_and_preprocess()\n",
    "num_classes=10\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epochs = 25** garantiza suficientes iteraciones para conseguir una presición alta del modelo.\n",
    "\n",
    "El **batch size de 4** es suficiente para una precisón de *93%*, sin embargo, si se tiene una capacidad de computo alta un batchsize de 1 sería lo ideal. Por otro lado un **batch size de 32** es suficiente para una precisión de *92%*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 15ms/step - accuracy: 0.2669 - loss: 2.1879 - val_accuracy: 0.7360 - val_loss: 1.4843\n",
      "Epoch 2/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10ms/step - accuracy: 0.6171 - loss: 1.3764 - val_accuracy: 0.8197 - val_loss: 0.7375\n",
      "Epoch 3/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.9028 - val_accuracy: 0.8527 - val_loss: 0.5398\n",
      "Epoch 4/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 11ms/step - accuracy: 0.7647 - loss: 0.7377 - val_accuracy: 0.8751 - val_loss: 0.4548\n",
      "Epoch 5/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 11ms/step - accuracy: 0.7910 - loss: 0.6544 - val_accuracy: 0.8843 - val_loss: 0.4083\n",
      "Epoch 6/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 10ms/step - accuracy: 0.8086 - loss: 0.6082 - val_accuracy: 0.8936 - val_loss: 0.3761\n",
      "Epoch 7/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 11ms/step - accuracy: 0.8269 - loss: 0.5558 - val_accuracy: 0.8989 - val_loss: 0.3546\n",
      "Epoch 8/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 11ms/step - accuracy: 0.8332 - loss: 0.5353 - val_accuracy: 0.9034 - val_loss: 0.3363\n",
      "Epoch 9/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 10ms/step - accuracy: 0.8410 - loss: 0.5118 - val_accuracy: 0.9088 - val_loss: 0.3219\n",
      "Epoch 10/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 10ms/step - accuracy: 0.8503 - loss: 0.4861 - val_accuracy: 0.9110 - val_loss: 0.3124\n",
      "Epoch 11/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 10ms/step - accuracy: 0.8547 - loss: 0.4737 - val_accuracy: 0.9128 - val_loss: 0.3020\n",
      "Epoch 12/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 10ms/step - accuracy: 0.8599 - loss: 0.4566 - val_accuracy: 0.9155 - val_loss: 0.2935\n",
      "Epoch 13/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 10ms/step - accuracy: 0.8674 - loss: 0.4379 - val_accuracy: 0.9186 - val_loss: 0.2851\n",
      "Epoch 14/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 10ms/step - accuracy: 0.8678 - loss: 0.4299 - val_accuracy: 0.9204 - val_loss: 0.2774\n",
      "Epoch 15/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10ms/step - accuracy: 0.8737 - loss: 0.4119 - val_accuracy: 0.9224 - val_loss: 0.2712\n",
      "Epoch 16/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.8749 - loss: 0.4182 - val_accuracy: 0.9238 - val_loss: 0.2661\n",
      "Epoch 17/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.8802 - loss: 0.4021 - val_accuracy: 0.9251 - val_loss: 0.2595\n",
      "Epoch 18/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.8812 - loss: 0.3945 - val_accuracy: 0.9266 - val_loss: 0.2533\n",
      "Epoch 19/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.8841 - loss: 0.3867 - val_accuracy: 0.9281 - val_loss: 0.2485\n",
      "Epoch 20/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 10ms/step - accuracy: 0.8888 - loss: 0.3744 - val_accuracy: 0.9296 - val_loss: 0.2432\n",
      "Epoch 21/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 10ms/step - accuracy: 0.8885 - loss: 0.3713 - val_accuracy: 0.9308 - val_loss: 0.2392\n",
      "Epoch 22/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 10ms/step - accuracy: 0.8889 - loss: 0.3737 - val_accuracy: 0.9322 - val_loss: 0.2344\n",
      "Epoch 23/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 10ms/step - accuracy: 0.8930 - loss: 0.3636 - val_accuracy: 0.9331 - val_loss: 0.2302\n",
      "Epoch 24/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.8952 - loss: 0.3518 - val_accuracy: 0.9335 - val_loss: 0.2263\n",
      "Epoch 25/25\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 10ms/step - accuracy: 0.8969 - loss: 0.3404 - val_accuracy: 0.9347 - val_loss: 0.2227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ae9f683a70>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=4, epochs=25,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2226763665676117\n",
      "Test accuracy: 0.9347000122070312\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursoDeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
